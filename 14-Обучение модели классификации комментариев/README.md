#  [Проект классификации комментариев c BERT](https://github.com/WhiteNivis/praktikum/tree/main/13-Прогнозирование%20количества%20заказов%20такси%20на%20следующий%20час)

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Требуется обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности правок.

<font color='green'>Цель</font>

Выбрать оптимальную модель для предсказания риска ДТП.

<font color='green'>Задачи</font>

- исследовать данные;
- подготовить данные;
- построить модель классификации комментариев со значением метрики качества *F1* не меньше 0.75;


<font color='green'>Файлы</font>

- `toxic_comments.csv` 


<font color='green'>Признаки</font>

- `text` — текст комментария

<font color='green'>Целевой признак</font>

- `toxic` 



## Общий вывод


В проекте независимо друг от друга использовались 2 метода подготовки признаков для задачи NLP:
 - TfidfVectorizer
 - предобученная модель `bert-base-uncased`.

Стоит отметить, что второй метод потребовал значительно больше времени чем первый (около 1 часа работы на `gpu`) и показал себя на всех моделях хуже первого. 

В тесте участвовали следующие модели: `LogisticRegression`, `LGBM`. 

Лучший результат:

МОДЕЛЬ с лучшим значением F1 на валидации: LogisticRegression
BERT model: false
F1 на валидации:  0.7775
F1 на test:  0.7932
Параметры лучшей модели: {'clf__C': 14}
Общее время: 00:06:16
