{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2133796b",
   "metadata": {},
   "source": [
    "# Проект классификации комментариев c BERT\n",
    "\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Требуется обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "<font color='green'>Цель</font>\n",
    "\n",
    "Выбрать оптимальную модель для предсказания риска ДТП.\n",
    "\n",
    "<font color='green'>Задачи</font>\n",
    "\n",
    "- исследовать данные;\n",
    "- подготовить данные;\n",
    "- построить модель классификации комментариев со значением метрики качества *F1* не меньше 0.75;\n",
    "\n",
    "\n",
    "<font color='green'>Файлы</font>\n",
    "\n",
    "- `toxic_comments.csv` \n",
    "\n",
    "\n",
    "<font color='green'>Признаки</font>\n",
    "\n",
    "- `text` — текст комментария\n",
    "\n",
    "<font color='green'>Целевой признак</font>\n",
    "\n",
    "- `toxic` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c896597",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-и-анализ\" data-toc-modified-id=\"Загрузка-и-анализ-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузка и анализ</a></span></li><li><span><a href=\"#Обработка-текста\" data-toc-modified-id=\"Обработка-текста-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Обработка текста</a></span></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#TfidfVectorizer\" data-toc-modified-id=\"TfidfVectorizer-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>TfidfVectorizer</a></span></li><li><span><a href=\"#BertModel\" data-toc-modified-id=\"BertModel-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>BertModel</a></span></li></ul></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8fe699",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe00bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import  f1_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pymorphy2\n",
    "from string import punctuation\n",
    "import re\n",
    "import torch\n",
    "from torch import cuda\n",
    "import transformers \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import spacy\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import notebook\n",
    "import json\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdbb422",
   "metadata": {},
   "source": [
    "### Загрузка и анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff951d69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159446  \":::::And for the second time of asking, when ...      0\n",
       "159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159449  And it looks like it was actually you who put ...      0\n",
       "159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth1 = '/ML/datasets/toxic_comments.csv'\n",
    "pth2 = 'toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    data = pd.read_csv(pth1, index_col=[0], parse_dates=[0])\n",
    "elif os.path.exists(pth2):\n",
    "    data = pd.read_csv(pth2, index_col=[0], parse_dates=[0])\n",
    "else:\n",
    "    print('Something is wrong')\n",
    "    \n",
    "# для BERT    \n",
    "model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e35230d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a7c1578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef317ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184abdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3fdc58",
   "metadata": {},
   "source": [
    "### Обработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "196c0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89fd720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_bag(doc):\n",
    "    \n",
    "    text = ' '.join([i for i in doc.lower().split() if i not in stop_words]) # строчные буквы + без стоп-слов\n",
    "    text = re.sub(r'[^a-zA-Z\\'\\-]', ' ', text) \n",
    "    text = re.sub(r'\\s+', ' ', text) # только одинарные пробелы\n",
    "    text = text.strip() # без пробел в начале/конце\n",
    "    return text\n",
    "\n",
    "def preprocess_text_bert(doc):\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-Z\\'\\-]', ' ', doc) \n",
    "    text = re.sub(r'\\s+', ' ', text) # только одинарные пробелы\n",
    "    text = text.strip() # без пробел в начале/конце\n",
    "    \n",
    "    return text\n",
    "\n",
    "def lemma_text(doc):\n",
    "    text = nlp(doc)\n",
    "    text = ' '.join([token.lemma_ for token in text])\n",
    "    return text\n",
    "\n",
    "def tokenize_bert(doc): \n",
    "    text = tokenizer.encode(doc, add_special_tokens=True, truncation=True, max_length=512) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c669dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemma'] = [preprocess_text_bag(t) for t in data['text']]\n",
    "data['lemma_BERT'] = [preprocess_text_bert(t) for t in data['text']]\n",
    "data['len'] = [len(t) for t in data['lemma_BERT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f633bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11min 21s\n",
      "Wall time: 11min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemma = [lemma_text(t) for t in data['lemma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "616d0e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 42s\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemma_bert = [tokenize_bert(t) for t in data['lemma_BERT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a00893",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd1f90",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93e75435",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = lemma\n",
    "target = data['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=12345, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e863aee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143362,) (15930,) (143362,) (15930,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(features_train).shape, np.array(features_test).shape, target_train.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c17e4",
   "metadata": {},
   "source": [
    "#### BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcbe5c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "features_bert = lemma_bert\n",
    "target_bert = data['toxic']\n",
    "\n",
    "model = model_class.from_pretrained(pretrained_weights)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "max_len = 0\n",
    "for i in features_bert:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e1afba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_transform(df):\n",
    "    padded = np.array([i + [0]*(max_len - len(i)) for i in df])\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "    batch_size = 100\n",
    "    embeddings = []\n",
    "    for i in notebook.tqdm(range(padded.shape[0] // batch_size +1)):\n",
    "        batch = torch.cuda.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.cuda.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n",
    "        \n",
    "    features = np.concatenate(embeddings)        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8edc890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33be1cc188494956ad3af153030f9966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_bert = bert_transform(features_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac097b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143362, 768) (15930, 768) (143362,) (15930,)\n"
     ]
    }
   ],
   "source": [
    "features_bert_train, features_bert_test, target_bert_train, target_bert_test = train_test_split(\n",
    "    features_bert, target_bert, test_size=0.1, random_state=12345, stratify=target_bert)\n",
    "\n",
    "print(features_bert_train.shape, features_bert_test.shape, target_bert_train.shape, target_bert_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6860ce14",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539879f3",
   "metadata": {},
   "source": [
    "Пропусков и дубликатов в данных не выявлено. Длину списка токенов ограничили 512 для возможности использовать предобученную модель `'bert-base-uncased'`. Для подготовки признаков было решено использовать параллельно 2 метода:\n",
    " - TfidfVectorizer\n",
    " - BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6230f",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61270a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# очистка памяти\n",
    "\n",
    "model = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# функция для подсчета времени\n",
    "\n",
    "def exec_time(start, end):\n",
    "    diff_time = end - start\n",
    "    m, s = divmod(diff_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    s,m,h = int(round(s, 0)), int(round(m, 0)), int(round(h, 0))\n",
    "    \n",
    "    return \"{0:02d}:{1:02d}:{2:02d}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9490b6cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Модель: LogisticRegression\n",
      "\n",
      "BERT model: false\n",
      "Лучшие параметры : {'clf__C': 13}\n",
      "Лучшее значение F1 на валидации: 0.7791\n",
      "Общее время: 00:06:19\n",
      "\n",
      "\n",
      "Модель: LogisticRegression\n",
      "\n",
      "BERT model: true\n",
      "Лучшие параметры : {'C': 14}\n",
      "Лучшее значение F1 на валидации: 0.7250\n",
      "Общее время: 00:36:11\n",
      "\n",
      "\n",
      "Модель: LGBM\n",
      "\n",
      "BERT model: false\n",
      "Лучшие параметры : {'clf__learning_rate': 0.3}\n",
      "Лучшее значение F1 на валидации: 0.7760\n",
      "Общее время: 00:04:06\n",
      "\n",
      "\n",
      "Модель: LGBM\n",
      "\n",
      "BERT model: true\n",
      "Лучшие параметры : {'learning_rate': 0.25}\n",
      "Лучшее значение F1 на валидации: 0.6769\n",
      "Общее время: 00:03:38\n",
      "\n",
      "\n",
      "МОДЕЛЬ с лучшим значением F1 на валидации: LogisticRegression\n",
      "BERT model: false\n",
      "F1 на валидации:  0.7791\n",
      "Параметры лучшей модели: {'clf__C': 13}\n",
      "Общее время: 00:06:19\n"
     ]
    }
   ],
   "source": [
    "сlassifiers = [\n",
    "                LogisticRegression(max_iter=1000),\n",
    "                LGBMClassifier(random_state = 12345)\n",
    "              ]\n",
    "\n",
    "сlassifiers_dict = {0: 'LogisticRegression',\n",
    "                    1: 'LGBM'}\n",
    "\n",
    "param = {\n",
    "             0:{'clf__C': range(5,16,1)},\n",
    "             1:{'clf__learning_rate': [0.1, 0.25, 0.3, 0.5]},\n",
    "                 \n",
    "             2:{'C': range(5,16,1)},\n",
    "             3:{'learning_rate': [0.1, 0.25, 0.3, 0.5]}\n",
    "    \n",
    "        }\n",
    "\n",
    "\n",
    "best_F1 = 0\n",
    "best_param = 0\n",
    "best_model = ''\n",
    "best_model_index = ''\n",
    "index = 0\n",
    "t = 0\n",
    "bert_status = ''\n",
    "\n",
    "\n",
    "def best(test=False):\n",
    "    print('\\nМОДЕЛЬ с лучшим значением F1 на валидации: {}'.format(best_model_index))\n",
    "    print('BERT model: {}'.format(bert_status))\n",
    "    print('F1 на валидации:  {:.4f}'.format(best_F1))\n",
    "    if test == True:\n",
    "            print('F1 на test:  {:.4f}'.format(F1))\n",
    "    print('Параметры лучшей модели:', best_param)\n",
    "    print(\"Общее время:\", t)\n",
    "\n",
    "  \n",
    "f1 = make_scorer(f1_score)\n",
    "\n",
    "count_tf_idf = TfidfVectorizer()\n",
    "\n",
    "for reg in сlassifiers:\n",
    "    for bert in ['false', 'true']:\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "        ('vect', count_tf_idf),\n",
    "        ('clf', reg)\n",
    "                    ]) \n",
    "               \n",
    "        if bert == 'false':     \n",
    "            model = GridSearchCV(pipeline, param_grid=param[index], scoring=f1, cv=3) \n",
    "            model.fit(features_train, target_train)\n",
    "        if bert == 'true':  \n",
    "            model = GridSearchCV(pipeline[1], param_grid=param[index+2], scoring=f1, cv=3) \n",
    "            model.fit(features_bert_train, target_bert_train)\n",
    "                           \n",
    "        if model.best_score_ > best_F1:\n",
    "            best_F1 = model.best_score_\n",
    "            best_model_index = сlassifiers_dict[index]\n",
    "            best_model = reg\n",
    "            bert_status = bert\n",
    "            best_param = model.best_params_ \n",
    "            end_1 = time.time() \n",
    "            t = exec_time(start,end_1)\n",
    "        \n",
    "            # сохранение модели\n",
    "            final_model = 'finalized_model.sav'\n",
    "            pickle.dump(model, open(final_model, 'wb'))\n",
    "            \n",
    "            with open('config.json', 'w') as f:\n",
    "                json.dump(best_param, f)\n",
    "            \n",
    "        \n",
    "        end = time.time()    \n",
    "        print('\\nМодель: {}'.format(сlassifiers_dict[index]))\n",
    "        print('\\nBERT model: {}'.format(bert))\n",
    "        print('Лучшие параметры : {}'.format(model.best_params_))\n",
    "        print('Лучшее значение F1 на валидации: {:.4f}'.format(model.best_score_))\n",
    "        print(\"Общее время:\", exec_time(start,end))\n",
    "        print()\n",
    "    index += 1\n",
    "    \n",
    "best()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659dea6d",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ee57dee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "МОДЕЛЬ с лучшим значением F1 на валидации: LogisticRegression\n",
      "BERT model: false\n",
      "F1 на валидации:  0.7791\n",
      "Параметры лучшей модели: {'clf__C': 13}\n",
      "Общее время: 00:06:19\n"
     ]
    }
   ],
   "source": [
    "best()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53bc27d",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070840a6",
   "metadata": {},
   "source": [
    "Проверим лучшую модель на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d989e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 лучшей модели на test:   0.7958\n"
     ]
    }
   ],
   "source": [
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "model_1 = pickle.load(open(final_model, 'rb')) # загрузка модели\n",
    "model_1.set_params(param_grid=config)\n",
    "\n",
    "if bert_status == 'true':\n",
    "    F1 = model_1.score(list(features_bert_test), list(target_bert_test))    \n",
    "\n",
    "if bert_status == 'false':\n",
    "    F1 = model_1.score(list(features_test), list(target_test))\n",
    "    \n",
    "print('F1 лучшей модели на test:   {:.4f}'.format(F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d0e22b",
   "metadata": {},
   "source": [
    "Проверим модель на адекватность, сравнив с исскуственной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "112e0816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Стратегия модели: stratified\n",
      "F1 модели на test:  0.1097\n",
      "\n",
      "Стратегия модели: uniform\n",
      "F1 модели на test:  0.1653\n"
     ]
    }
   ],
   "source": [
    "strategies = ['stratified', 'uniform']\n",
    "\n",
    "for strategy in strategies:\n",
    "\n",
    "    baseline_model = DummyClassifier(strategy=strategy)\n",
    "    baseline_model.fit(features_train, target_train)\n",
    "\n",
    "    predicted = baseline_model.predict(features_test)\n",
    "    \n",
    "    print('\\nСтратегия модели:', strategy)\n",
    "    print('F1 модели на test:  {:.4f}'.format(f1_score(target_test, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5605dd1",
   "metadata": {},
   "source": [
    "Необходимый порог для F1 (0.75) достигнут. Модель прошла проверку на адекватность. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ef834",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ed854",
   "metadata": {},
   "source": [
    "В проекте независимо друг от друга использовались 2 метода подготовки признаков для задачи NLP:\n",
    " - TfidfVectorizer\n",
    " - предобученная модель `bert-base-uncased`.\n",
    "\n",
    "Стоит отметить, что второй метод потребовал значительно больше времени чем первый (около 1 часа работы на `gpu`) и показал себя на всех моделях хуже первого. \n",
    "\n",
    "В тесте участвовали следующие модели: `LogisticRegression`, `LGBM`. \n",
    "\n",
    "Лучший результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c27e3ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "МОДЕЛЬ с лучшим значением F1 на валидации: LogisticRegression\n",
      "BERT model: false\n",
      "F1 на валидации:  0.7791\n",
      "F1 на test:  0.7958\n",
      "Параметры лучшей модели: {'clf__C': 13}\n",
      "Общее время: 00:06:19\n"
     ]
    }
   ],
   "source": [
    "best(test=True)"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 96,
    "start_time": "2022-11-21T13:23:12.069Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
