{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d3aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e20b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import  f1_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import pymorphy2\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4efc7bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159446  \":::::And for the second time of asking, when ...      0\n",
       "159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159449  And it looks like it was actually you who put ...      0\n",
       "159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth1 = '/ML/datasets/toxic_comments.csv'\n",
    "pth2 = '/datasets/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    data = pd.read_csv(pth1, index_col=[0], parse_dates=[0])\n",
    "elif os.path.exists(pth2):\n",
    "    data = pd.read_csv(pth2, index_col=[0], parse_dates=[0])\n",
    "else:\n",
    "    print('Something is wrong')\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152c3d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 41.4 s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['and', 'im'])\n",
    "\n",
    "lemma = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(doc):\n",
    "    \n",
    "    text = ' '.join([i for i in doc.lower().split() if i not in stop_words])\n",
    "    text = ''.join(ch for ch in text if ch not in punctuation)\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    #text = \" \".join([lemma.parse(word)[0].normal_form for word in text.split(' ')])\n",
    "    return text\n",
    "\n",
    "data['lemma'] = [preprocess_text(t) for t in data['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c25013e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43432d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer(\n",
    "vocab_file='/datasets/ds_bert/vocab.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e337312",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RuBERT'] = tokenizer.encode(data['lemma'], add_special_tokens=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05889bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314741a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756681c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['lemma']\n",
    "target = data['toxic']\n",
    "\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.3, random_state=12345, stratify=target)\n",
    "\n",
    "print(features_train.shape, target_train.shape, features_test.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6bb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cbe03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac0b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee7fb15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e955ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a50d20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d98f6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(X, y, repeat):\n",
    "    features_zeros = X[y == 0]\n",
    "    features_ones = X[y == 1]\n",
    "    target_zeros = y[y == 0]\n",
    "    target_ones = y[y == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled.reset_index(drop=True), target_upsampled.reset_index(drop=True)\n",
    "\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features, target, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f4e1c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer() \n",
    "features_train = count_tf_idf.fit_transform(features_train) \n",
    "features_test = count_tf_idf.transform(features_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa6227a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ",
   "title_sidebar": "Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
